1
00:00:05,927 --> 00:00:08,895
TensorFlow 
2019年开发人员峰会

2
00:00:08,895 --> 00:00:09,814
大家早上好，

3
00:00:09,814 --> 00:00:15,493
我是TensorFlow的项目经理 Alina

4
00:00:15,493 --> 00:00:17,461
谢谢。

5
00:00:17,461 --> 00:00:20,929
欢迎参加2019年的
TensorFlow开发人员峰会。

6
00:00:20,929 --> 00:00:24,334
这是我们迄今为止举办的第三届年度
和规模最大的开发人员峰会，

7
00:00:24,334 --> 00:00:26,339
我很高兴大家都能来到这里

8
00:00:26,339 --> 00:00:28,601
也欢迎观看现场直播的观众们。

9
00:00:28,601 --> 00:00:29,624
欢迎。

10
00:00:29,624 --> 00:00:31,431
所以我只是有点好奇，可以举手示意，

11
00:00:31,431 --> 00:00:35,096
谁坐了很长的路途来到这儿？

12
00:00:35,096 --> 00:00:37,667
欧洲？

13
00:00:37,667 --> 00:00:39,788
亚洲？

14
00:00:39,788 --> 00:00:41,309
非洲？

15
00:00:41,309 --> 00:00:43,635
甚至澳大利亚？

16
00:00:43,635 --> 00:00:45,206
哇，太棒了。

17
00:00:45,206 --> 00:00:48,297
欢迎大家。

18
00:00:48,297 --> 00:00:52,367
我们接下来有很多很棒的演讲，
一些令人兴奋的公告和

19
00:00:52,367 --> 00:00:56,089
很酷的演示，所以让我们开始吧。

20
00:00:56,089 --> 00:00:59,350
我们现在生活在历史的形成时刻，

21
00:00:59,350 --> 00:01:03,079
机器学习正在经历一场前所未有的革命。

22
00:01:03,079 --> 00:01:06,155
我们对于计算机系统的思考和互动

23
00:01:06,155 --> 00:01:08,938
在本质上发生了变化，

24
00:01:08,938 --> 00:01:11,795
由于人工智能领域的突破。

25
00:01:11,795 --> 00:01:15,366
这是由于三个主要因素。

26
00:01:15,366 --> 00:01:20,866
首先，我们有更多的计算专门设计的ML加速器，

27
00:01:20,866 --> 00:01:22,647
比如这些TPU，

28
00:01:22,647 --> 00:01:28,439
让你可以比以前更快地训练模型。

29
00:01:28,439 --> 00:01:32,678
其次，我们在机器学习领域取得了突破。

30
00:01:32,678 --> 00:01:34,989
他们每个月创建的新颖算法，

31
00:01:34,989 --> 00:01:39,463
如BERT和自然语言处理的创新方法，

32
00:01:39,463 --> 00:01:41,145
让世界各地的任何人

33
00:01:41,145 --> 00:01:46,461
都可以训练他们自己最先进的问答系统。

34
00:01:46,461 --> 00:01:49,991
最后，我们有大量的数据。

35
00:01:49,991 --> 00:01:54,781
我们看到新的数据集来自各种学科。

36
00:01:54,781 --> 00:01:59,367
例如，新的打开图像扩展数据集。

37
00:01:59,367 --> 00:02:04,905
这是志愿者为追求

38
00:02:04,905 --> 00:02:08,430
包容性和多样性

39
00:02:08,430 --> 00:02:12,992
而增加的超过478,000张图片的集合。

40
00:02:12,992 --> 00:02:16,303
因此，所有这三个基本上都在改变

41
00:02:16,303 --> 00:02:19,577
我们解决有挑战性的现实世界问题的方式，

42
00:02:19,577 --> 00:02:23,263
而且看到TensorFlow成为推动

43
00:02:23,263 --> 00:02:27,390
这一机器学习革命的平台，真的很酷。

44
00:02:27,390 --> 00:02:31,890
它允许世界各地的开发人员，
企业和研究人员

45
00:02:31,890 --> 00:02:34,565
从智能应用程序中受益。

46
00:02:34,565 --> 00:02:36,308
我们对研发社区使用TensorFlow

47
00:02:36,308 --> 00:02:40,434
构建的内容感到非常惊讶。

48
00:02:40,434 --> 00:02:43,799
开发人员一直在
使用TensorFlow来解决

49
00:02:43,799 --> 00:02:46,881
当地社区的问题

50
00:02:46,881 --> 00:02:49,778
因此，我不知道在悲剧性的天堂大火期间

51
00:02:49,778 --> 00:02:51,938
你们是否有人刚好在湾区，

52
00:02:51,938 --> 00:02:53,518
但其中一个后果

53
00:02:53,518 --> 00:02:55,828
是空气质量非常糟糕。

54
00:02:55,828 --> 00:03:02,153
空气质量指数在200中段接近300。

55
00:03:02,153 --> 00:03:08,634
而在印度德里的冬天时。

56
00:03:08,634 --> 00:03:15,277
空气质量指数则可能达到
更糟糕的400s左右

57
00:03:15,277 --> 00:03:17,587
这被认为是非常危险的。

58
00:03:17,587 --> 00:03:20,840
因此污染传感器可以帮助测量空气质量，

59
00:03:20,840 --> 00:03:24,284
但是大规模部署它们非常昂贵。

60
00:03:24,284 --> 00:03:29,522
因此，德里的一群学生在TensorFlow中
构建了图像分类器，

61
00:03:29,522 --> 00:03:35,094
并使用这些分类器构建了
一个名为Air Cognizer的应用程序，

62
00:03:35,094 --> 00:03:40,678
它所做的事情基本上
就是使用智能手机上的图像。

63
00:03:40,678 --> 00:03:46,736
它可以准确估算空气质量。

64
00:03:46,736 --> 00:03:48,623
企业也在从根本上

65
00:03:48,623 --> 00:03:51,934
改进他们使用TensorFlow构建的
产品和服务，

66
00:03:51,934 --> 00:03:56,381
例如，它致力于为全球用户提供

67
00:03:56,381 --> 00:03:59,151
相关和工业健康的信息。

68
00:03:59,151 --> 00:04:00,294
但这可能很难，

69
00:04:00,294 --> 00:04:03,732
当用户关注数百甚至数千人时，

70
00:04:03,732 --> 00:04:08,052
为了解决这个问题，Twitter推出了
排名时间线，这是一个ML电源，

71
00:04:08,052 --> 00:04:11,067
在时间线的顶部有最相关的推文，

72
00:04:11,067 --> 00:04:14,116
确保用户永远不会错过他们
最好和最相关的内容。

73
00:04:14,116 --> 00:04:16,668
通过使用TensorFlow的工具生态系统

74
00:04:16,668 --> 00:04:19,081
如TensorFlow Hub，TensorBoard

75
00:04:19,081 --> 00:04:21,279
和TensorFlow模型分析，

76
00:04:21,279 --> 00:04:26,500
Twitter能够减少训练和模型迭代时间，

77
00:04:26,500 --> 00:04:32,350
并提高时间线质量和用户的参与度。

78
00:04:32,350 --> 00:04:36,877
ML正在大大的改变特定行业。

79
00:04:36,877 --> 00:04:38,592
例如，GE Healthcare

80
00:04:38,592 --> 00:04:41,282
正在使用TensorFlow来改善MRI成像。

81
00:04:41,282 --> 00:04:45,832
这些TensorFlow模型，
它们在MRI扫描仪上是实时的，

82
00:04:45,832 --> 00:04:50,110
并且真的可以检测扫描仪内部患者的方向。

83
00:04:50,110 --> 00:04:52,288
这真的很好

84
00:04:52,288 --> 00:04:55,356
因为这不仅有助于诊断，

85
00:04:55,356 --> 00:05:00,247
还可以减少错误和检查时间。

86
00:05:00,247 --> 00:05:05,936
而且，很酷的是它基本上将这项技术

87
00:05:05,936 --> 00:05:10,930
扩展到全世界更多的人。

88
00:05:10,930 --> 00:05:13,413
TensorFlow也在为最前沿的研究助力。

89
00:05:13,413 --> 00:05:16,837
位于 VIDYA 的 Oak Ridge 国家实验室的

90
00:05:16,837 --> 00:05:20,425
科学家，研究人员和工程师团队

91
00:05:20,425 --> 00:05:22,519
最近因使用高性能计算

92
00:05:22,519 --> 00:05:24,693
应用深度学习

93
00:05:24,693 --> 00:05:29,088
来研究极端天气模式的影响

94
00:05:29,088 --> 00:05:31,890
而获得戈登贝尔奖。

95
00:05:31,890 --> 00:05:36,635
他们使用TensorFlow建立
并扩展了一个神经网络，

96
00:05:36,635 --> 00:05:40,858
当然，用于在世界上最快的
超级计算机 Summit 的运行

97
00:05:40,858 --> 00:05:43,718
他们实现了 1.13 exaFLOPS 和 FPC-16

98
00:05:43,718 --> 00:05:45,887
的峰值和持续吞吐量，

99
00:05:45,887 --> 00:05:49,598
相当于每秒超过定量计算量。

100
00:05:49,598 --> 00:05:53,451
我想我需要暂停一秒，
因为那是超乎寻常的快。

101
00:05:53,451 --> 00:05:56,933
对吧？

102
00:05:56,933 --> 00:05:59,227
除了这些很好的例子之外，

103
00:05:59,227 --> 00:06:02,008
全世界有成千上万的人使用

104
00:06:02,008 --> 00:06:04,509
TensorFlow进行很好的工作，

105
00:06:04,509 --> 00:06:07,470
如果没有你们所有人，
TensorFlow的力量和影响

106
00:06:07,470 --> 00:06:10,106
就不会是现在这样，谢谢。

107
00:06:10,106 --> 00:06:13,281
在你的帮助和兴趣下，

108
00:06:13,281 --> 00:06:17,658
TensorFlow已成为世界上
最广泛采用的ML框架。

109
00:06:17,658 --> 00:06:21,666
就在这里，我想展示GitHub明星的最新地图，

110
00:06:21,666 --> 00:06:24,590
他们自我确定了他们的定位。

111
00:06:24,590 --> 00:06:26,916
我相信这张地图上的很多点

112
00:06:26,916 --> 00:06:28,639
都在这个房间和现场直播上，

113
00:06:28,639 --> 00:06:33,108
所以我只想再次感谢你们。

114
00:06:33,108 --> 00:06:35,125
这种增长十分令人惊叹。

115
00:06:35,125 --> 00:06:39,761
TensorFlow已被下载超过4100万次，

116
00:06:39,761 --> 00:06:45,214
并在全球拥有1800多名贡献者。

117
00:06:45,214 --> 00:06:48,611
去年11月，我们回顾了

118
00:06:48,611 --> 00:06:51,133
多年来我们添加的不同组件，

119
00:06:51,133 --> 00:06:53,758
庆祝了TensorFlow的第三个生日。

120
00:06:53,758 --> 00:06:55,190
但今天，我们想谈谈TensorFlow

121
00:06:55,190 --> 00:06:57,594
的平台如何逐渐成熟

122
00:06:57,594 --> 00:07:00,180
成为一个完整的 端到端生态系统。

123
00:07:00,180 --> 00:07:03,585
而TensorFlow 2.0是一个新时代的开始，

124
00:07:03,585 --> 00:07:05,702
我们致力于使其

125
00:07:05,702 --> 00:07:08,970
成为所有用户的最佳ML平台。

126
00:07:08,970 --> 00:07:11,052
为了更多地谈论TensorFlow 2.0，

127
00:07:11,052 --> 00:07:12,729
我想在舞台上介绍TensorFlow的

128
00:07:12,729 --> 00:07:16,657
工程总监Rajat Monga。

129
00:07:16,657 --> 00:07:22,276
谢谢。

130
00:07:22,276 --> 00:07:24,518
谢谢，Alina。

131
00:07:24,518 --> 00:07:26,645
大家好，我是Rajat。

132
00:07:26,645 --> 00:07:28,170
我是TensorFlow的工程师，

133
00:07:28,170 --> 00:07:31,233
从一开始就参与其中。

134
00:07:31,233 --> 00:07:34,123
很高兴看到过去几年

135
00:07:34,123 --> 00:07:35,401
我们的努力。

136
00:07:35,401 --> 00:07:36,465
所有惊人的成长

137
00:07:36,465 --> 00:07:40,963
和你用它做过的所有很棒的事情。

138
00:07:40,963 --> 00:07:43,377
能听到你们的反馈我很高兴。

139
00:07:43,377 --> 00:07:45,477
告诉我们你对TensorFlow的期待，

140
00:07:45,477 --> 00:07:47,747
同样重要的是，
你希望在TensorFlow中

141
00:07:47,747 --> 00:07:48,858
看到哪些改进。

142
00:07:48,858 --> 00:07:51,800
你的反馈非常明确、清晰。

143
00:07:51,800 --> 00:07:56,184
你在开发人员体验中要求更简单，
更直观的API。

144
00:07:56,184 --> 00:07:59,436
你指出了有冗余和复杂性的部分，

145
00:07:59,436 --> 00:08:03,993
你还要求提供更好的文档和示例，

146
00:08:03,993 --> 00:08:08,194
这正是我们开发TensorFlow 2.0
一直在关注的事情。

147
00:08:08,194 --> 00:08:10,219
为了简单起见，我们在一组API上

148
00:08:10,219 --> 00:08:12,105
专注于Keras，

149
00:08:12,105 --> 00:08:16,009
并将其与Eager执行相结合，
以简化Python。

150
00:08:16,009 --> 00:08:18,858
可以灵活地尝试最疯狂的想法

151
00:08:18,858 --> 00:08:21,025
和超越exaFLOP的能力

152
00:08:21,025 --> 00:08:23,785
TensorFlow比以往任何时候都更强大。

153
00:08:23,785 --> 00:08:26,339
具有与在谷歌中进行的实战考验

154
00:08:26,339 --> 00:08:31,793
相同的稳健性和性能。

155
00:08:31,793 --> 00:08:34,765
让我们从TensorFlow
的整体架构开始。

156
00:08:34,765 --> 00:08:37,445
你可能会对这种高级架构感到熟悉。

157
00:08:37,445 --> 00:08:39,563
多年来，我们添加了

158
00:08:39,563 --> 00:08:41,422
许多组件和功能，

159
00:08:41,422 --> 00:08:45,231
以帮助支持从训练到部署的工作负载。

160
00:08:45,231 --> 00:08:47,467
使用TensorFlow 2.0，
我们确实可以确保

161
00:08:47,467 --> 00:08:52,031
这些组件更好地协同工作。

162
00:08:52,031 --> 00:08:54,889
以下是这些功能强大的API组件

163
00:08:54,889 --> 00:08:56,881
如何适用于整个训练工作流程。

164
00:08:56,881 --> 00:09:00,210
使用 tf.data 进行数据摄取和转换，

165
00:09:00,210 --> 00:09:03,682
使用模型构建的 keras 和 预制估算器，

166
00:09:03,682 --> 00:09:06,011
使用 eager执行 和 图形 进行训练，

167
00:09:06,011 --> 00:09:12,298
最后使用 SavedModel 进行包装。

168
00:09:12,298 --> 00:09:15,163
我们来看看一些例子。

169
00:09:15,163 --> 00:09:16,959
你需要的第一个东西就是数据。

170
00:09:16,959 --> 00:09:19,944
通常，你可能希望验证结果或

171
00:09:19,944 --> 00:09:22,793
在常见公共数据集中测试新想法。

172
00:09:22,793 --> 00:09:24,087
TensorFlow数据集包括

173
00:09:24,087 --> 00:09:27,150
一个庞大且快速增长的公共数据集集合，

174
00:09:27,150 --> 00:09:29,751
你可以非常轻松地开始使用它们。

175
00:09:29,751 --> 00:09:30,988
结合 tf.data，

176
00:09:30,988 --> 00:09:35,525
包装自己的数据也很简单。

177
00:09:35,525 --> 00:09:38,034
以下是可用数据集的一小部分试品，

178
00:09:38,034 --> 00:09:44,277
其中包含所有这些以及更多的数据集。

179
00:09:44,277 --> 00:09:47,357
然后使用keras，你可以用层来表达模型，

180
00:09:47,357 --> 00:09:50,064
就像你一惯的想法。

181
00:09:50,064 --> 00:09:52,931
标准训练和评估也包含在

182
00:09:52,931 --> 00:09:58,931
model.fit 和 .evaluate 中。

183
00:09:58,931 --> 00:10:02,284
由于深度学习模型的计算成本通常很高，

184
00:10:02,284 --> 00:10:05,748
因此你可能需要尝试在多个设备上
对它进行扩展。

185
00:10:05,748 --> 00:10:07,931
TensorFlow预先构建了
MirroredStrategy，

186
00:10:07,931 --> 00:10:14,861
可以对代码进行少量添加。

187
00:10:14,861 --> 00:10:17,422
从预先训练的模型或组件开始

188
00:10:17,422 --> 00:10:21,105
也可以很好地减少一些计算成本。

189
00:10:21,105 --> 00:10:22,248
为简单起见，

190
00:10:22,248 --> 00:10:25,558
TensorFlow Hub提供了
大量预先训练过的组件，

191
00:10:25,558 --> 00:10:27,136
你可以将这些组件包含在你的模型中，

192
00:10:27,136 --> 00:10:33,451
甚至可以针对特定数据集进行微调。

193
00:10:33,451 --> 00:10:36,769
Keras 和 .estimator
为易于使用的包

194
00:10:36,769 --> 00:10:38,706
提供高级构建块。

195
00:10:38,706 --> 00:10:43,208
它们为你提供典型训练工作所需的一切。

196
00:10:43,208 --> 00:10:45,704
但是，有时你需要更多的控制。

197
00:10:45,704 --> 00:10:51,695
例如，当你正在探索新类型的算法时。

198
00:10:51,695 --> 00:10:55,567
比方说，你想构建一个用于机器翻译
的自定义编码器。

199
00:10:55,567 --> 00:10:58,406
以下是通过子类化模型来实现此目的的方法。

200
00:10:58,406 --> 00:10:59,407
在这里，你可以专注于

201
00:10:59,407 --> 00:11:01,812
实行计算算法，

202
00:11:01,812 --> 00:11:05,437
并让框架处理其余的事情。

203
00:11:05,437 --> 00:11:07,207
你甚至可以自定义训练循环

204
00:11:07,207 --> 00:11:15,689
以完全控制渐变和优化过程。

205
00:11:15,689 --> 00:11:16,896
在训练模型时，

206
00:11:16,896 --> 00:11:19,523
无论是使用keras
还是更复杂的模型包装，

207
00:11:19,523 --> 00:11:22,257
了解进度，

208
00:11:22,257 --> 00:11:25,145
甚至详细分析模型通常都很有用。

209
00:11:25,145 --> 00:11:28,964
TensorBoard 提供了大量的
可视化功能来帮助解决这个问题，

210
00:11:28,964 --> 00:11:31,070
现在它与 intercollab

211
00:11:31,070 --> 00:11:33,616
和其他 Jupiter 笔记本完全集成，

212
00:11:33,616 --> 00:11:35,753
让你可以直接在笔记本中

213
00:11:35,753 --> 00:11:40,271
看到相同的可视化效果。

214
00:11:40,271 --> 00:11:44,904
所有这些功能
都在TensorFlow 2.0中提供，

215
00:11:44,904 --> 00:11:47,619
我很高兴地宣布我们的alpha版本

216
00:11:47,619 --> 00:11:56,415
在今天发布了。

217
00:11:56,415 --> 00:11:58,511
在这里，以及全世界的你们，

218
00:11:58,511 --> 00:12:02,510
真的帮忙完成了大量的测试工作，
才得以实现这次的发布。

219
00:12:02,510 --> 00:12:05,281
我真的很想借这一刻感谢大家。

220
00:12:05,281 --> 00:12:07,406
请给自己掌声作为鼓励。

221
00:12:07,406 --> 00:12:17,151
没有你们，我们真的无法做到它。

222
00:12:17,151 --> 00:12:19,921
除了我们讨论过的所有重大改进之外，

223
00:12:19,921 --> 00:12:21,558
此版本还附带了一个转换脚本，

224
00:12:21,558 --> 00:12:23,599
可帮助你从1.X.升级，

225
00:12:23,599 --> 00:12:27,121
以及一个兼容性模块，
可让你访问1.X. API，

226
00:12:27,121 --> 00:12:30,075
让过渡变得更容易。

227
00:12:30,075 --> 00:12:36,861
我们正努力在下一季度进行全面发布。

228
00:12:36,861 --> 00:12:39,616
还有很多工作要做，
从而让TensorFlow 2.0

229
00:12:39,616 --> 00:12:41,263
对你有更大的帮助。

230
00:12:41,263 --> 00:12:43,500
你可以跟踪进度并在

231
00:12:43,500 --> 00:12:51,109
TensorFlow GitHub项目页面上
提供反馈。

232
00:12:51,109 --> 00:12:52,768
你要求提供更好的文档，

233
00:12:52,768 --> 00:13:00,939
我们致力于简化 API，指南 和 教程。

234
00:13:00,939 --> 00:13:02,838
所有这些材料将于今天

235
00:13:02,838 --> 00:13:05,726
在重新设计的
TensorFlow.org网站上公布。

236
00:13:05,726 --> 00:13:10,412
你会在哪里找到更多的例子，
文档和工具来开始。

237
00:13:10,412 --> 00:13:11,459
我们对这些变化以及

238
00:13:11,459 --> 00:13:14,697
即将发生的变化感到非常兴奋。

239
00:13:14,697 --> 00:13:16,816
也非常兴奋想告诉你
更多关于TensorFlow

240
00:13:16,816 --> 00:13:18,045
在研究和生产方面的改进。

241
00:13:18,045 --> 00:13:20,134
我想欢迎 Megan Kacholia 上台，

242
00:13:20,134 --> 00:13:28,023
谢谢。

243
00:13:28,023 --> 00:13:29,158
谢谢，Rajat。

244
00:13:29,158 --> 00:13:32,425
TensorFlow一直是研究生产的平台。

245
00:13:32,425 --> 00:13:34,679
我们刚刚看到TensorFlow
作为高级API，

246
00:13:34,679 --> 00:13:37,306
可以让你轻松入门并构建模型。

247
00:13:37,306 --> 00:13:40,999
现在，我们来谈谈它如何改进
研究人员的强大实验，

248
00:13:40,999 --> 00:13:43,235
把你从模型研究和原型制作

249
00:13:43,235 --> 00:13:45,876
带到生产。

250
00:13:45,876 --> 00:13:48,972
研究人员一直在使用TensorFlow
进行最前卫的研究。

251
00:13:48,972 --> 00:13:50,835
我们可以在纸质出版物中看到它，

252
00:13:50,835 --> 00:13:54,636
它在过去几年中在这张图表中被显示出来。

253
00:13:54,636 --> 00:13:58,690
但强大的实验的开始真的需要灵活性。

254
00:13:58,690 --> 00:14:01,637
这始于TensorFlow的
Eager执行。

255
00:14:01,637 --> 00:14:06,334
默认情况下，在TensorFlow 2.0中，
每个Python命令都将被立即执行。

256
00:14:06,334 --> 00:14:09,009
这意味着你可以使用你习惯的样式编写代码，

257
00:14:09,009 --> 00:14:10,968
而无需使用 Session.Run

258
00:14:10,968 --> 00:14:14,668
这也会对调试领域产生重大影响。

259
00:14:14,668 --> 00:14:16,137
当你使用Eager模式进行迭代时，

260
00:14:16,137 --> 00:14:19,447
你将最终希望将代码分发到GPU，TPU

261
00:14:19,447 --> 00:14:21,514
和其他硬件或加速器上。

262
00:14:21,514 --> 00:14:23,341
为此，我们提供了 tf.function，

263
00:14:23,341 --> 00:14:26,858
它将你eager的代码转换为图形，
函数对函数。

264
00:14:26,858 --> 00:14:28,351
你可以获得所有熟悉的工具，

265
00:14:28,351 --> 00:14:31,208
如Python，控制流，插入，甚至打印，

266
00:14:31,208 --> 00:14:34,803
但可以随时在你需要时转换为图形，

267
00:14:34,803 --> 00:14:37,817
包括你准备好让模型进入生产中时。

268
00:14:37,817 --> 00:14:41,232
即便如此，你仍将获得良好的调试。

269
00:14:41,232 --> 00:14:43,711
调试能力很强，不仅仅是在Eager中，

270
00:14:43,711 --> 00:14:46,815
但是我们在 tf.function 和图形方面
也做了很大的改进。

271
00:14:46,815 --> 00:14:48,323
在这里显示的这个例子中，

272
00:14:48,323 --> 00:14:51,634
我们使用 tf.function 分割 tensor，
这将创建了一个图形，

273
00:14:51,634 --> 00:14:54,478
但是由于输入不匹配，你会得到一个错误。

274
00:14:54,478 --> 00:14:56,698
如你所见，我们现在向用户提供

275
00:14:56,698 --> 00:14:59,727
有关文件的信息
以及模型中发生错误的行号，

276
00:14:59,727 --> 00:15:01,329
以帮助你更快地找出问题所在，

277
00:15:01,329 --> 00:15:03,307
以便继续迭代。

278
00:15:03,307 --> 00:15:07,587
我们使错误消息简洁，易于理解和可操作。

279
00:15:07,587 --> 00:15:10,289
我们希望你喜欢这些变化，
它们使你可以更轻松地

280
00:15:10,289 --> 00:15:14,336
快速迭代和推进你的模型进度。

281
00:15:14,336 --> 00:15:16,557
性能是我们所知道的另一个

282
00:15:16,557 --> 00:15:19,576
研究人员以及所有用户关注领域，

283
00:15:19,576 --> 00:15:22,553
我们一直在改进TensorFlow
的核心性能。

284
00:15:22,553 --> 00:15:23,644
自去年以来，

285
00:15:23,644 --> 00:15:28,251
我们加快了近一倍
8台 NVIDIA Tesla V100 的训练。

286
00:15:28,251 --> 00:15:30,505
使用Google Cloud TPU V2，

287
00:15:30,505 --> 00:15:33,092
我们将性能提升了1.6倍。

288
00:15:33,092 --> 00:15:35,103
通过英特尔MKL加速，

289
00:15:35,103 --> 00:15:38,127
我们的推理速度提高了近三倍。

290
00:15:38,127 --> 00:15:41,334
性能将继续成为
TensorFlow 2.0的重点，

291
00:15:41,334 --> 00:15:45,329
也是我们最终版本发展的核心部分。

292
00:15:45,329 --> 00:15:48,655
TensorFlow还为研究人员提供了灵活性，

293
00:15:48,655 --> 00:15:50,313
灵活性来自于许多的附加库，

294
00:15:50,313 --> 00:15:52,480
以新的和有用的方式

295
00:15:52,480 --> 00:15:54,273
扩展TensorFlow。

296
00:15:54,273 --> 00:15:56,129
其中一些附加库或扩展

297
00:15:56,129 --> 00:15:57,469
可以使某些问题更容易解决，

298
00:15:57,469 --> 00:15:59,406
例如带有Unicode的 TF.Text

299
00:15:59,406 --> 00:16:01,416
和新的参差不齐的Tensor类型。

300
00:16:01,416 --> 00:16:03,203
在其他情况下，它让我们探索

301
00:16:03,203 --> 00:16:06,259
如何通过TF隐私使机器学习模型

302
00:16:06,259 --> 00:16:08,039
更公平和更安全。

303
00:16:08,039 --> 00:16:11,726
你还将听到有关强化学习
的TF-Agents的更新

304
00:16:11,726 --> 00:16:14,584
明天，我们将讨论用于联合学习

305
00:16:14,584 --> 00:16:18,059
的新TF联合库。

306
00:16:18,059 --> 00:16:21,126
深度学习研究也正在使用TensorFlow

307
00:16:21,126 --> 00:16:22,526
应用于真实世界的应用。

308
00:16:22,526 --> 00:16:25,118
以下是谷歌研究人员的一些示例，

309
00:16:25,118 --> 00:16:27,817
他们将其应用于数据中心等领域。

310
00:16:27,817 --> 00:16:30,311
我们通过可实现节能的AI控制系统

311
00:16:30,311 --> 00:16:32,332
提高效率。

312
00:16:32,332 --> 00:16:34,923
我们的应用程序如谷歌地图，
中间显示的应用程序，

313
00:16:34,923 --> 00:16:38,270
具有称为全球本地化的新导航功能。

314
00:16:38,270 --> 00:16:42,072
它结合了视觉定位服务，街景和机器学习，

315
00:16:42,072 --> 00:16:45,248
以更准确地识别位置和方向。

316
00:16:45,248 --> 00:16:47,228
像 Google Pixel 这样的设备

317
00:16:47,228 --> 00:16:49,777
使用机器学习来改善深度估算，

318
00:16:49,777 --> 00:16:51,572
以创建更好的肖像模式照片，

319
00:16:51,572 --> 00:16:54,679
如此处所示。

320
00:16:54,679 --> 00:16:57,251
为了使这些真实世界的应用程序成为现实，

321
00:16:57,251 --> 00:17:00,293
你必须能够从研究和原型设计中获取模型。

322
00:17:00,293 --> 00:17:02,273
一直到发布和生产。

323
00:17:02,273 --> 00:17:05,601
这一直是TensorFlow的
核心力量和专注点。

324
00:17:05,601 --> 00:17:07,601
使用TensorFlow，
你可以在许多平台上部署模型

325
00:17:07,601 --> 00:17:10,037
如此处所示。

326
00:17:10,037 --> 00:17:11,728
模型最终会出现在很多地方出现，

327
00:17:11,728 --> 00:17:13,688
因此我们希望确保TensorFlow

328
00:17:13,688 --> 00:17:16,483
在服务器和云端，

329
00:17:16,483 --> 00:17:18,491
手机和其他Edge设备，

330
00:17:18,491 --> 00:17:20,675
浏览器和JavaScript平台上
都能很好地运作。

331
00:17:20,675 --> 00:17:22,382
我们有针对以下所有的产品：

332
00:17:22,382 --> 00:17:25,644
TensorFlow Extended，
TensorFlow Lite和TensorFlow.js，

333
00:17:25,644 --> 00:17:28,931
我将简要介绍一下。

334
00:17:28,931 --> 00:17:31,256
TensorFlow Extended是我们用于

335
00:17:31,256 --> 00:17:34,078
管理机器学习生命周期
各个阶段的端到端平台

336
00:17:34,078 --> 00:17:37,233
它贯穿从提取和转换你的数据到

337
00:17:37,233 --> 00:17:39,919
大规模部署机器学习模型。

338
00:17:39,919 --> 00:17:44,245
在这里显示的橙色中，
你可以看到到目前为止开源的库。

339
00:17:44,245 --> 00:17:45,630
这张幻灯片需要传达的是，

340
00:17:45,630 --> 00:17:47,079
我们现在更进一步，

341
00:17:47,079 --> 00:17:49,309
提供构建端到端平台的这些库

342
00:17:49,309 --> 00:17:51,801
构建的组件。

343
00:17:51,801 --> 00:17:53,333
请注意，这些是

344
00:17:53,333 --> 00:17:54,587
在数千个生产系统内部

345
00:17:54,587 --> 00:17:56,119
使用的相同组件，

346
00:17:56,119 --> 00:17:59,638
为谷歌最重要的产品提供支持。

347
00:17:59,638 --> 00:18:01,739
这些组件只是故事的一部分。

348
00:18:01,739 --> 00:18:04,082
2019年是我们将它们整合在一起的一年，

349
00:18:04,082 --> 00:18:07,612
并为你提供集成的端到端平台。

350
00:18:07,612 --> 00:18:09,766
首先，你可以携带自己的协调器。

351
00:18:09,766 --> 00:18:13,299
在这里，我们会展示 airflow 或 kubeflow，
甚至是原始的 kubernetes，

352
00:18:13,299 --> 00:18:14,659
你想要哪个都可以。

353
00:18:14,659 --> 00:18:16,474
无论你选择哪种协调器，

354
00:18:16,474 --> 00:18:19,943
TensorFlow扩展组件
都会与元数据存储集成。

355
00:18:19,943 --> 00:18:22,287
这个商店跟踪所有”运行“组件，

356
00:18:22,287 --> 00:18:24,622
进入它们的工件

357
00:18:24,622 --> 00:18:26,810
以及生成的工件。

358
00:18:26,810 --> 00:18:30,091
这样可以实现高级功能，如实验，进行实验

359
00:18:30,091 --> 00:18:32,688
和实验跟踪，模型比较

360
00:18:32,688 --> 00:18:33,982
以及类似的功能，

361
00:18:33,982 --> 00:18:35,565
我确信你会对那些功能感到兴奋，

362
00:18:35,565 --> 00:18:37,764
并在你迭代和制作

363
00:18:37,764 --> 00:18:40,102
你的生产系统时帮助你。

364
00:18:40,102 --> 00:18:43,126
我们今天晚些时候将与
Clemens及其团队进行端到端的讨论，

365
00:18:43,126 --> 00:18:44,972
他们将带你全面了解

366
00:18:44,972 --> 00:18:49,390
使用TensorFlow Extended
来解决真实的问题。

367
00:18:49,390 --> 00:18:52,355
继续，TensorFlow Lite
是我们在手机和物联网硬件上

368
00:18:52,355 --> 00:18:54,064
运行模型的解决方案。

369
00:18:54,064 --> 00:18:57,898
它使用自定义流线型文件格式
和精简运行时，

370
00:18:57,898 --> 00:19:01,587
以便你可以在用户所在的任何地方
部署TensorFlow模型。

371
00:19:01,587 --> 00:19:05,278
设备模型可能比云后端对输入更敏感，

372
00:19:05,278 --> 00:19:07,719
并且它们将用户数据
保存在设备上以保护隐私，

373
00:19:07,719 --> 00:19:10,336
这非常重要，尤其是在当今时代。

374
00:19:10,336 --> 00:19:13,898
谷歌和我们在中国的IGE合作伙伴
使用TF Lite

375
00:19:13,898 --> 00:19:15,328
在各种工具中，

376
00:19:15,328 --> 00:19:18,707
包括预测文本生成，视频分割

377
00:19:18,707 --> 00:19:21,805
和边缘检测等。

378
00:19:21,805 --> 00:19:24,654
但在引擎盖下，
TensorFlow Lite是关乎性能的。

379
00:19:24,654 --> 00:19:28,175
你可以将模型部署到CPU，
GPU甚至Edge TPU，

380
00:19:28,175 --> 00:19:29,918
并可以预测快速的性能，

381
00:19:29,918 --> 00:19:33,433
自从我们去年推出了TensorFlow 
Lite以来，我们一直在进行改进。

382
00:19:33,433 --> 00:19:36,417
通过在CPU上使用最新的量化技术，

383
00:19:36,417 --> 00:19:40,192
在GPU上添加对OpenGL 3.1
和Metal的支持，

384
00:19:40,192 --> 00:19:42,633
以及调整我们在Edge TPU上的性能，

385
00:19:42,633 --> 00:19:46,327
我们不断突破在设备上的极限，

386
00:19:46,327 --> 00:19:50,199
在未来一年，你应该可以期待更大的进步。

387
00:19:50,199 --> 00:19:52,843
我们将在今天早上稍后一些听到

388
00:19:52,843 --> 00:19:56,186
Raziel 和他的同事分享的细节内容。

389
00:19:56,186 --> 00:19:58,901
Javascript 是世界上最好的编程语言，

390
00:19:58,901 --> 00:20:01,282
直到最近，它都还没有从所有的

391
00:20:01,282 --> 00:20:03,851
机器学习开发和工具中受益。

392
00:20:03,851 --> 00:20:06,271
去年，我们发布了TensorFlow.js，

393
00:20:06,271 --> 00:20:08,967
这是一个用于在 浏览器 和 Node.js 上

394
00:20:08,967 --> 00:20:11,392
训练和部署机器学习模型的库。

395
00:20:11,392 --> 00:20:14,351
从那时起，我们已经看到
JavaScript社区的大量采用，

396
00:20:14,351 --> 00:20:18,111
拥有超过300,000次下载
和100个贡献者，

397
00:20:18,111 --> 00:20:19,404
但鉴于JavaScript和Web生态系统

398
00:20:19,404 --> 00:20:23,562
的规模庞大，我们只是刚刚开始而已。

399
00:20:23,562 --> 00:20:27,229
今天我们很高兴地宣布
TensorFlow.js 版本1.0

400
00:20:27,229 --> 00:20:29,932
这带来了许多改进和新功能。

401
00:20:29,932 --> 00:20:34,064
我们有一个现成的模型库，
用于在浏览器和节点上

402
00:20:34,064 --> 00:20:36,675
运行的常见机器学习问题。

403
00:20:36,675 --> 00:20:38,922
我们还增加了对运行JavaScript

404
00:20:38,922 --> 00:20:42,047
的平台增加更多的支持，例如电子桌面应用程序

405
00:20:42,047 --> 00:20:44,359
或手机平台。

406
00:20:44,359 --> 00:20:47,590
TensorFlow.js 1.0 的一个重点

407
00:20:47,590 --> 00:20:49,302
是性能改进。

408
00:20:49,302 --> 00:20:51,434
例如，与去年相比，

409
00:20:51,434 --> 00:20:55,148
MobileNet推理和浏览器的速度
提高了9倍。

410
00:20:55,148 --> 00:20:59,870
你将在今天迟些时候的演讲中
了解有关这些进展的更多信息。

411
00:20:59,870 --> 00:21:02,794
另一种另我们很兴奋的语言是swift。

412
00:21:02,794 --> 00:21:04,747
TensorFlow的Swift正在重新审视

413
00:21:04,747 --> 00:21:07,290
性能和可用性的意义。

414
00:21:07,290 --> 00:21:10,020
在TensorFlow的核心基础上
构建了一个新的堆栈，

415
00:21:10,020 --> 00:21:11,242
以及一个旨在进一步提高

416
00:21:11,242 --> 00:21:14,829
可用性的新编程模型。

417
00:21:14,829 --> 00:21:19,051
今天，我们宣布TensorFlow
的Swift现在的版本为0.2。

418
00:21:19,051 --> 00:21:21,596
它已准备好让你进行试验，试用，

419
00:21:21,596 --> 00:21:25,868
我们很高兴能将它带到社区。

420
00:21:25,868 --> 00:21:28,416
除了告诉你版本0.2之外，

421
00:21:28,416 --> 00:21:31,687
我们还很高兴地宣布，
Jeremy Howard，一个fast.ai

422
00:21:31,687 --> 00:21:34,480
正在为TensorFlow
在Swift里写一个新课程。

423
00:21:34,480 --> 00:21:39,534
Chris和Brennan今天晚些时候
会告诉你更多相关信息。

424
00:21:39,534 --> 00:21:41,904
所以回顾一下
到目前为止我们向你展示的一切。

425
00:21:41,904 --> 00:21:44,281
TensorFlow已经发展成为
一个完整的生态系统，

426
00:21:44,281 --> 00:21:45,732
从研究到生产，

427
00:21:45,732 --> 00:21:48,825
从服务器到手机，并且使用多种语言。

428
00:21:48,825 --> 00:21:50,793
这种增长是由我们的社区推动的，

429
00:21:50,793 --> 00:21:53,720
如果没有社区，老实说是不可能的。

430
00:21:53,720 --> 00:21:57,190
为了谈谈我们在2019年为你的计划
和将和你一起计划的东西，

431
00:21:57,190 --> 00:22:03,684
我要把舞台交给Kemal。

432
00:22:03,684 --> 00:22:05,510
都是你的了。

433
00:22:05,510 --> 00:22:07,286
谢谢你，Megan。

434
00:22:07,286 --> 00:22:08,818
嗨，我的名字是Kemal，

435
00:22:08,818 --> 00:22:11,733
我是TensorFlow的产品总监。

436
00:22:11,733 --> 00:22:16,216
我很高兴今天能够参加这个庆祝活动，

437
00:22:16,216 --> 00:22:18,629
我们庆祝的是我们正在建设的

438
00:22:18,629 --> 00:22:21,627
最重要的部分，那就是社区。

439
00:22:21,627 --> 00:22:24,334
就个人而言，我喜欢构建开发人员平台。

440
00:22:24,334 --> 00:22:26,826
我曾经是一名企业家兼开发人员，

441
00:22:26,826 --> 00:22:29,168
现在我通过建立一个更好的平台

442
00:22:29,168 --> 00:22:32,810
来启用其他开发人员。

443
00:22:32,810 --> 00:22:34,477
当我们开始研究2.0时，

444
00:22:34,477 --> 00:22:36,574
我们转向社区，

445
00:22:36,574 --> 00:22:38,993
我们从共同流程的请求开始，

446
00:22:38,993 --> 00:22:42,749
就重要的产品决策咨询你们所有人。

447
00:22:42,749 --> 00:22:44,521
我们收到了有价值的反馈

448
00:22:44,521 --> 00:22:48,324
如果没有你们，我们将无法建立2.0。

449
00:22:48,324 --> 00:22:50,476
有些人想要参与更多，

450
00:22:50,476 --> 00:22:53,501
所以我们创建了特殊的兴趣小组

451
00:22:53,501 --> 00:22:56,717
或者像Networking或
Tensor Board的sig。

452
00:22:56,717 --> 00:22:58,940
对于社区而言，
sig真的是一种很好的方式

453
00:22:58,940 --> 00:23:00,750
来构建他们最关心的

454
00:23:00,750 --> 00:23:04,014
TensorFlow的部分。

455
00:23:04,014 --> 00:23:06,229
我们还想了解更多关于你正在构建的内容，

456
00:23:06,229 --> 00:23:08,906
因此我们推出了
Powered By TensorFlow活动。

457
00:23:08,906 --> 00:23:12,669
我要说的是，我们对项目的创造性感到惊讶，

458
00:23:12,669 --> 00:23:15,940
从生物图像分析到定制可穿戴设备，

459
00:23:15,940 --> 00:23:18,544
再到聊天应用 BOTS

460
00:23:18,544 --> 00:23:22,101
社区成立之后的三年，
我们见证了她的蓬勃发展。

461
00:23:22,101 --> 00:23:26,057
现在有将近70台机器学习GTE。

462
00:23:26,057 --> 00:23:27,198
在全世界各个角落，

463
00:23:27,198 --> 00:23:30,092
仅核心就有1800名贡献者，

464
00:23:30,092 --> 00:23:33,000
无数人正在做着很棒的工作

465
00:23:33,000 --> 00:23:35,161
来帮助TensorFlow取得成功。

466
00:23:35,161 --> 00:23:37,543
所以代表整个TensorFlow团队，

467
00:23:37,543 --> 00:23:45,740
我们想说一声谢谢。

468
00:23:45,740 --> 00:23:47,884
所以2019年我们有很大计划，

469
00:23:47,884 --> 00:23:51,336
我想宣布一些消息。

470
00:23:51,336 --> 00:23:53,582
首先，随着我们社区的发展，

471
00:23:53,582 --> 00:23:56,217
我们欢迎那些刚接触机器学习的人，

472
00:23:56,217 --> 00:23:57,900
为他们提供最好的教育材料

473
00:23:57,900 --> 00:24:00,675
非常重要，

474
00:24:00,675 --> 00:24:03,700
所以我们很高兴地宣布

475
00:24:03,700 --> 00:24:05,880
两个新的在线课程。

476
00:24:05,880 --> 00:24:07,793
一个是deeplearning.ai，

477
00:24:07,793 --> 00:24:10,201
它在Coursera平台上发布。

478
00:24:10,201 --> 00:24:12,510
另一个是Udacity。

479
00:24:12,510 --> 00:24:16,590
这些课程的第一批现在已可用，

480
00:24:16,590 --> 00:24:20,653
它们为开发人员提供了
TensorFlow 的精彩介绍

481
00:24:20,653 --> 00:24:23,558
你不需要有机器学习的知识，

482
00:24:23,558 --> 00:24:27,134
因此我强烈建议你去看一看。

483
00:24:27,134 --> 00:24:30,651
接下来，如果你是新注册的学生，

484
00:24:30,651 --> 00:24:33,571
你可以申请谷歌代码的夏天的计划，

485
00:24:33,571 --> 00:24:36,332
并与TensorFlow工程团队合作，

486
00:24:36,332 --> 00:24:40,788
帮助构建TensorFlow的一部分。

487
00:24:40,788 --> 00:24:44,096
我刚才还谈到了
Powered By TensorFlow 活动

488
00:24:44,096 --> 00:24:46,715
我们对其创造力感到非常兴奋实，

489
00:24:46,715 --> 00:24:50,839
我们决定在DevPost帖子上
推出 2.0 hackathon

490
00:24:50,839 --> 00:24:53,039
让你分享你最新最好的，

491
00:24:53,039 --> 00:24:55,053
并赢得很酷的奖品。

492
00:24:55,053 --> 00:24:59,934
所以我们很兴奋想看看到你将构建什么。

493
00:24:59,934 --> 00:25:02,815
最后，随着我们的生态系统的发展，

494
00:25:02,815 --> 00:25:04,652
我们现在正处于峰会的第二天，

495
00:25:04,652 --> 00:25:08,229
但我们真的想做更多的事情。

496
00:25:08,229 --> 00:25:10,139
我们想要一个可以分享

497
00:25:10,139 --> 00:25:12,486
你在TensorFlow上建立的内容的地方，

498
00:25:12,486 --> 00:25:15,586
因此我们很高兴地宣布

499
00:25:15,586 --> 00:25:17,286
TensorFlow World大会，

500
00:25:17,286 --> 00:25:21,876
这是一个为期一周的开源式协作会议。

501
00:25:21,876 --> 00:25:25,969
本次会议将由O'Reilly Media
和TensorFlow共同主办，

502
00:25:25,969 --> 00:25:29,126
并将于10月底在Santa Clara举行。

503
00:25:29,126 --> 00:25:32,936
我们的愿景是聚集大家参与
TensorFlow World大会，

504
00:25:32,936 --> 00:25:36,611
并为人们提供相互联系的空间。

505
00:25:36,611 --> 00:25:39,469
所以我想邀请Gina Blaber在舞台上

506
00:25:39,469 --> 00:25:48,065
介绍关于该会议的内容。

507
00:25:48,065 --> 00:25:50,537
谢谢你，Kemal。

508
00:25:50,537 --> 00:25:52,252
O'Reilly是一家专注于技术和商业

509
00:25:52,252 --> 00:25:55,330
的学习型公司。

510
00:25:55,330 --> 00:25:57,009
正如你们许多人所知，

511
00:25:57,009 --> 00:25:59,429
我们与开源社区有着密切的关系，

512
00:25:59,429 --> 00:26:03,555
而且我们有将实现大创意的先例。

513
00:26:03,555 --> 00:26:06,865
这就是为什么我们很高兴能
与TensorFlow合作

514
00:26:06,865 --> 00:26:08,089
创建这个将机器学习和AI

515
00:26:08,089 --> 00:26:12,800
带入社区的新活动。

516
00:26:12,800 --> 00:26:16,499
TensorFlow活动于10月28日至31日

517
00:26:16,499 --> 00:26:17,989
在Santa Clara举行。

518
00:26:17,989 --> 00:26:21,172
当我说社区时，我指的是每个人。

519
00:26:21,172 --> 00:26:24,445
我们希望将整个TensorFlow社区的

520
00:26:24,445 --> 00:26:26,630
个人和团队

521
00:26:26,630 --> 00:26:28,231
以及企业整合在一起。

522
00:26:28,231 --> 00:26:30,135
在这里，你将会遇到

523
00:26:30,135 --> 00:26:31,430
来自世界各地的专家，

524
00:26:31,430 --> 00:26:33,808
创建了TensorFlow的团队

525
00:26:33,808 --> 00:26:38,985
以及将帮助你部署它的公司和企业。

526
00:26:38,985 --> 00:26:43,339
我们现在在TensorFlow World网站上
有一个开放的CFP。

527
00:26:43,339 --> 00:26:47,131
我邀请大家看一下并尽快发送你的提案，

528
00:26:47,131 --> 00:26:49,342
以便大家共享你的想法。

529
00:26:49,342 --> 00:26:52,520
我们期待在十月份的
TensorFlow World大会见到你。

530
00:26:52,520 --> 00:26:58,452
谢谢。

531
00:26:58,452 --> 00:27:00,153
谢谢你，Gina。这将很棒。

532
00:27:00,153 --> 00:27:02,401
你们兴奋吗？

533
00:27:02,401 --> 00:27:05,026
Woo！

534
00:27:05,026 --> 00:27:07,314
我号召大家一起来参与这些活动

535
00:27:07,314 --> 00:27:10,336
参加一个课程，
向TF World大会提交你的方案，

536
00:27:10,336 --> 00:27:12,136
开始体验2.0

537
00:27:12,136 --> 00:27:15,303
顺便说一句，DevPost上的 hackathon 奖

538
00:27:15,303 --> 00:27:19,832
将包括TensorFlow World大会的免费门票。

539
00:27:19,832 --> 00:27:23,641
你知道我最喜欢的一件事就是听到

540
00:27:23,641 --> 00:27:26,978
人们在TensorFlow上建造
一些很棒东西的故事。

541
00:27:26,978 --> 00:27:30,383
作为一个团对，我们真的相信
当人们可以使用我们的工具时，

542
00:27:30,383 --> 00:27:32,626
人工智能会更快速地发展，

543
00:27:32,626 --> 00:27:35,871
然后以前无古人的方式将它们

544
00:27:35,871 --> 00:27:38,592
应用到他们关心的问题中。

545
00:27:38,592 --> 00:27:43,345
当人们真的可以做到这一点时，
会发生一些特别的事情。

546
00:27:43,345 --> 00:27:51,511
我想和你分享一些非常特别的东西。

547
00:27:51,511 --> 00:27:53,169
查看历史文件，

548
00:27:53,169 --> 00:27:55,543
特别是中世纪的文件，

549
00:27:55,543 --> 00:28:01,893
需要大量的时间和耐心。

550
00:28:01,893 --> 00:28:07,128
在梵蒂冈档案馆，有85公里的文件

551
00:28:07,128 --> 00:28:09,874
大约是巴拿马运河的长度。

552
00:28:09,874 --> 00:28:12,197
用中世纪笔迹书写的经文

553
00:28:12,197 --> 00:28:14,555
与我们现在所知的不同。

554
00:28:14,555 --> 00:28:18,024
如果有一天有人要我转录并翻译

555
00:28:18,024 --> 00:28:20,811
梵蒂冈档案馆的所有文件，

556
00:28:20,811 --> 00:28:23,053
我会告诉他们，他们是彻底疯了。

557
00:28:23,053 --> 00:28:25,220
逐页查看本书

558
00:28:25,220 --> 00:28:28,773
并试图破译，阅读和转录所有内容

559
00:28:28,773 --> 00:28:32,376
需要花费大量时间。

560
00:28:32,376 --> 00:28:36,505
这将需要一支古代绘画大军。

561
00:28:36,505 --> 00:28:39,690
我对机器学习最感兴趣的是

562
00:28:39,690 --> 00:28:42,086
它使我们能够解决

563
00:28:42,086 --> 00:28:45,911
长达10年，15年前我们认为无法解决的问题。

564
00:28:45,911 --> 00:28:49,316
“In Codice Ratio”诞生于
这种构建软件的想法，

565
00:28:49,316 --> 00:28:52,980
该软件可以阅读和解析这些手稿中的内容。

566
00:28:52,980 --> 00:28:55,689
当我们开始讨论这个问题时，

567
00:28:55,689 --> 00:28:58,030
我们意识到基于神经网络的解决方案

568
00:28:58,030 --> 00:29:00,442
是绝对必要的。

569
00:29:00,442 --> 00:29:04,610
选择TensorFlow是很自然的。

570
00:29:04,610 --> 00:29:08,055
在使用任何类型的机器学习模块之前，

571
00:29:08,055 --> 00:29:09,627
我们需要先收集数据。

572
00:29:09,627 --> 00:29:13,287
你在互联网上有成千上万的狗和猫的图像，

573
00:29:13,287 --> 00:29:17,301
但是很少有古代手稿的图像。

574
00:29:17,301 --> 00:29:21,570
我们为群众外包构建了自己的
自定义Web应用程序，

575
00:29:21,570 --> 00:29:26,828
我们让高中学生收集数据。

576
00:29:26,828 --> 00:29:29,336
我对机器学习一般都不太了解，

577
00:29:29,336 --> 00:29:34,283
但我发现创建TensorFlow环境
非常容易。

578
00:29:34,283 --> 00:29:38,260
当我们试图找出最适合我们的模型时，

579
00:29:38,260 --> 00:29:39,936
Keras是最好的解决方案。

580
00:29:39,936 --> 00:29:44,604
生产模型在TensorFlow图层和
估算器界面上运行。

581
00:29:44,604 --> 00:29:47,515
我们用完全连接的网络

582
00:29:47,515 --> 00:29:49,285
进行二元分类试验，

583
00:29:49,285 --> 00:29:52,646
最后我们转向卷积神经网络

584
00:29:52,646 --> 00:29:54,497
和多类分类。

585
00:29:54,497 --> 00:30:00,052
在短时间内，我们得以开发和测试
第一个解决方案。

586
00:30:00,052 --> 00:30:02,664
在识别单个字符时，

587
00:30:02,664 --> 00:30:06,121
我们可以获得95％的平均准确度。

588
00:30:06,121 --> 00:30:11,276
能够使用一个IT工具大大缩短了时间。

589
00:30:11,276 --> 00:30:14,768
能够解答某些缩写并理解

590
00:30:14,768 --> 00:30:17,427
隐藏式写作中的文本

591
00:30:17,427 --> 00:30:19,268
是非常难能可贵的。

592
00:30:19,268 --> 00:30:22,810
这将在短时间内产生巨大影响。

593
00:30:22,810 --> 00:30:27,110
我们将提供大量的历史信息。

594
00:30:27,110 --> 00:30:29,927
我只是觉得解决问题很有趣。

595
00:30:29,927 --> 00:30:32,167
这是对我自己的一场游戏，

596
00:30:32,167 --> 00:30:34,277
以及我能做得多好。

597
00:30:34,277 --> 00:30:37,329
历史的研究

598
00:30:37,329 --> 00:30:39,702
对于理解我们的现状

599
00:30:39,702 --> 00:30:51,705
和了解未来非常重要。

600
00:30:51,705 --> 00:30:53,563
这是一个很棒的故事。

601
00:30:53,563 --> 00:30:57,500
我想到写这些手稿的学者们。

602
00:30:57,500 --> 00:31:00,366
他们无法想象，几个世纪之后，

603
00:31:00,366 --> 00:31:03,270
人们将使用计算机将他们的工作呈现。

604
00:31:03,270 --> 00:31:05,778
所以我们真的很幸运
今天有Elena和我们在一起。

605
00:31:05,778 --> 00:31:16,060
Elena，你可以站起来吗？

606
00:31:16,060 --> 00:31:19,276
不要错过今天她将分享她的故事的演讲。

607
00:31:19,276 --> 00:31:20,764
我真的希望你有美好的一天。

608
00:31:20,764 --> 00:31:22,551
我们有一些非常棒的东西。

609
00:31:22,551 --> 00:31:24,969
我和团队将会在这附近。

610
00:31:24,969 --> 00:31:27,536
请过来打个招呼，我们希望听听你的意见，

611
00:31:27,536 --> 00:31:30,474
然后我将把舞台交给Martin，

612
00:31:30,474 --> 00:31:32,204
他将谈论TensorFlow 2.0

613
00:31:32,204 --> 00:31:32,974
谢谢

